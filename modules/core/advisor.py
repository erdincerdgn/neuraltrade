"""
AI Advisor Slim Edition - RAG-Enhanced Trading Advisor
Author: Erdinc Erdogan
Purpose: Provides hedge fund-level AI trading advice using Qdrant vector search and
LangChain with Ollama LLM for intelligent market analysis and recommendations.
References:
- Retrieval Augmented Generation (RAG)
- Qdrant Vector Database
- LangChain Framework
Usage:
    advisor = AIAdvisor()
    recommendation = advisor.analyze_trade(ticker="AAPL", tech_signals=signals)
"""

import os
import re
from typing import List, Dict, Optional, Tuple
from datetime import datetime
from pathlib import Path
from colorama import Fore, Style

from qdrant_client import QdrantClient, models
from langchain_qdrant import QdrantVectorStore, FastEmbedSparse, RetrievalMode
from langchain_community.embeddings import FastEmbedEmbeddings
from langchain_ollama import OllamaLLM
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.documents import Document
from langchain_core.output_parsers import StrOutputParser
from flashrank import Ranker, RerankRequest

# Cross-Encoder
try:
    from sentence_transformers import CrossEncoder
    CROSS_ENCODER_AVAILABLE = True
except ImportError:
    CROSS_ENCODER_AVAILABLE = False

# yfinance
try:
    import yfinance as yf
    YFINANCE_AVAILABLE = True
except ImportError:
    YFINANCE_AVAILABLE = False

# ============================================
# MODÃœLER Ä°MPORTLAR
# ============================================
from .base import QueryType, QueryComplexity
from .memory import SQLiteMemory

# RAG SÄ±nÄ±flarÄ± (inline - Ã§Ã¼nkÃ¼ Ã¶zele has)
from ..intelligence.corrective import CorrectiveRAG
from ..intelligence.reranker import CrossEncoderReranker
from ..intelligence.graph import KnowledgeGraph, PropertyGraph

# Intelligence
from ..intelligence.vision import VisionRAG
from ..intelligence.agentic import AgenticToolUse
from ..intelligence.orchestrator import ModelOrchestrator
from ..intelligence.router import SemanticRouter, AdaptiveRAG

# RAG Helper SÄ±nÄ±flarÄ±
from ..intelligence.repl import PythonREPL
from ..intelligence.extractor import TradeRuleExtractor


# ============================================
# MAIN AI ADVISOR CLASS
# ============================================
class AIAdvisor:
    """
    Hedge Fund AI Level Trading Advisor.
    40+ Ã¶zellik modÃ¼ler yapÄ±da entegre.
    """
    
    def __init__(self, user_id: str = "default"):
        self.ollama_host = os.getenv("OLLAMA_HOST", "http://ollama-service:11434")
        self.qdrant_url = os.getenv("QDRANT_URL", "http://qdrant-service:6333")
        self.user_id = user_id
        
        self.child_collection = "neural_trade_pro"
        self.parent_collection = "neural_trade_parent"
        
        # Core Components
        self.llm = OllamaLLM(model="llama3", base_url=self.ollama_host)
        self.dense_embeddings = FastEmbedEmbeddings(model_name="BAAI/bge-small-en-v1.5")
        self.sparse_embeddings = FastEmbedSparse(model_name="Qdrant/bm25")
        self.client = QdrantClient(url=self.qdrant_url)
        self.bi_encoder = Ranker(model_name="ms-marco-MultiBERT-L-12")
        
        self.vectorstore = QdrantVectorStore(
            client=self.client,
            collection_name=self.child_collection,
            embedding=self.dense_embeddings,
            sparse_embedding=self.sparse_embeddings,
            retrieval_mode=RetrievalMode.HYBRID,
            vector_name="dense",
            sparse_vector_name="sparse",
        )
        
        # AI Lab Components
        self.memory = SQLiteMemory()
        self.crag = CorrectiveRAG(self.llm)
        self.cross_encoder = CrossEncoderReranker()
        self.repl = PythonREPL()
        self.graph = KnowledgeGraph()
        self.rule_extractor = TradeRuleExtractor(self.llm)
        
        # Dynamic Intelligence
        self.agentic = AgenticToolUse(self.llm)
        self.vision = VisionRAG(self.ollama_host)
        
        # Hedge Fund AI
        self.property_graph = PropertyGraph(self.llm)
        self.orchestrator = ModelOrchestrator(self.ollama_host)

    def _batch_fetch_parents(self, docs: List[Document]) -> List[Document]:
        """Optimized parent fetch."""
        parent_ids = list(set(d.metadata.get("parent_id") for d in docs if d.metadata.get("parent_id")))
        if not parent_ids:
            return docs
        
        try:
            results = self.client.scroll(
                collection_name=self.parent_collection,
                scroll_filter=models.Filter(must=[
                    models.FieldCondition(key="metadata.parent_id", match=models.MatchAny(any=parent_ids))
                ]),
                limit=min(len(parent_ids), 100),
                with_payload=True
            )
            
            if not results[0]:
                return docs
            
            parent_map = {p.payload.get("metadata", {}).get("parent_id"): Document(
                page_content=p.payload.get("page_content", ""),
                metadata=p.payload.get("metadata", {})
            ) for p in results[0]}
            
            expanded = []
            seen = set()
            for doc in docs:
                pid = doc.metadata.get("parent_id")
                if pid and pid in parent_map and pid not in seen:
                    expanded.append(parent_map[pid])
                    seen.add(pid)
            
            return expanded if expanded else docs
        except:
            return docs

    def _execute_calculation(self, query: str, tech_signals: str) -> str:
        """Python REPL ile finansal hesaplama yap."""
        calc_keywords = ["pip", "lot", "kaldÄ±raÃ§", "leverage", "pozisyon", "risk"]
        if not any(kw in query.lower() or kw in tech_signals.lower() for kw in calc_keywords):
            return ""
        
        print(f"{Fore.MAGENTA}  â†’ Python REPL: Hesaplama yapÄ±lÄ±yor...{Style.RESET_ALL}", flush=True)
        
        results = []
        results.append(self.repl.calculate_risk_reward(1.0850, 1.0800, 1.0950))
        results.append(self.repl.calculate_position_size(10000, 2, 50))
        
        if results:
            return f"\nğŸ PYTHON HESAPLAMALARI:\n  â€¢ " + "\n  â€¢ ".join(results) + "\n"
        return ""

    def _get_prompt(self, use_full: bool = True) -> str:
        if use_full:
            return """Sen AI Lab seviyesinde bir algoritmik trade danÄ±ÅŸmanÄ±sÄ±n.

<user_profile>
{personalization}
</user_profile>

<past_performance>
{past_performance}
</past_performance>

<graph_rag>
{graph_context}
</graph_rag>

<calculations>
{calculations}
</calculations>

<technical_data ticker="{ticker}">
{tech_signals}
Piyasa: {market_sentiment}
{fact_check}
</technical_data>

<strategies>
{context}
</strategies>

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ§  CHAIN-OF-THOUGHT ANALÄ°Z
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**ADIM 1 - TEKNÄ°K ANALÄ°Z:** Verileri analiz et.
**ADIM 2 - KÄ°TAP STRATEJÄ°LERÄ°:** Ã–nerileri Ã§Ä±kar.
**ADIM 3 - KULLANICI PROFÄ°LÄ°:** Risk toleransÄ±na gÃ¶re ayarla.
**ADIM 4 - GEÃ‡MÄ°Å PERFORMANS:** Ã–nceki hatalardan ders al.
**ADIM 5 - EKONOMÄ°K Ä°LÄ°ÅKÄ°LER:** Graph-RAG'dan Ã§Ä±karÄ±mlar.
**ADIM 6 - HESAPLAMALAR:** Python REPL sonuÃ§larÄ±nÄ± deÄŸerlendir.
**ADIM 7 - RÄ°SK DEÄERLENDÄ°RMESÄ°:** 2+ risk belirt.
**ADIM 8 - NÄ°HAÄ° KARAR:** 'AL ğŸŸ¢', 'SAT ğŸ”´' veya 'BEKLE ğŸŸ¡'

ANALÄ°Z:"""
        else:
            return """Trade danÄ±ÅŸmanÄ±sÄ±n.
<user_profile>{personalization}</user_profile>
<graph_rag>{graph_context}</graph_rag>
<calculations>{calculations}</calculations>
<technical_data ticker="{ticker}">{tech_signals}</technical_data>
Piyasa: {market_sentiment}
{fact_check}
<strategies>{context}</strategies>
AL/SAT/BEKLE Ã¶ner:"""

    def analyze_trade(self, ticker: str, tech_signals: str, market_sentiment: str = "NÃ¶tr"):
        """
        Hedge Fund AI Level Trading Analizi.
        
        Pipeline: Semantic Router â†’ Adaptive RAG â†’ Hybrid Search â†’ 
        Bi-Encoder â†’ C-RAG â†’ Cross-Encoder â†’ Parent Fetch â†’ 
        Trade Rules â†’ Python REPL â†’ Graph-RAG â†’ Memory â†’ LLM
        """
        base_query = f"{ticker} iÃ§in {tech_signals} verileri ile hangi strateji kullanÄ±lmalÄ±?"
        
        # 1. Router
        if SemanticRouter.classify(base_query) == QueryType.GENERAL:
            return "Merhaba! ğŸ‘‹ Ben NeuralTrade AI Lab. Trading sorunuz var mÄ±? ğŸ“ˆ"
        
        # 2. Adaptive RAG
        complexity = AdaptiveRAG.assess(base_query)
        strategy = AdaptiveRAG.get_strategy(complexity)
        
        print(f"\n{Fore.YELLOW}[AI] {strategy['desc']} - {complexity.value.upper()}{Style.RESET_ALL}", flush=True)
        print(f"{Fore.CYAN}[AI] {ticker} iÃ§in AI LAB analiz baÅŸlatÄ±lÄ±yor...{Style.RESET_ALL}", flush=True)
        
        # 3. Hybrid Search
        docs = self.vectorstore.as_retriever(search_kwargs={"k": strategy["top_k"]}).invoke(base_query)
        print(f"{Fore.GREEN}  â†’ {len(docs)} dÃ¶kÃ¼man bulundu{Style.RESET_ALL}", flush=True)
        
        # 4. Bi-Encoder Reranking
        if len(docs) > 1:
            passages = [{"id": i, "text": d.page_content} for i, d in enumerate(docs)]
            rerank = self.bi_encoder.rerank(RerankRequest(query=base_query, passages=passages))
            docs = [docs[r["id"]] for r in rerank[:7]]
            print(f"{Fore.GREEN}  â†’ Bi-Encoder: {len(docs)} dÃ¶kÃ¼man{Style.RESET_ALL}", flush=True)
        
        # 5. C-RAG (Alaka KontrolÃ¼)
        web_news = ""
        if strategy["use_crag"]:
            print(f"{Fore.MAGENTA}  â†’ C-RAG: Alaka kontrolÃ¼...{Style.RESET_ALL}", flush=True)
            original_count = len(docs)
            docs = self.crag.filter_documents(base_query, docs)
            print(f"{Fore.GREEN}  â†’ C-RAG: {len(docs)} alakalÄ± dÃ¶kÃ¼man{Style.RESET_ALL}", flush=True)
            
            if len(docs) < original_count * 0.3:
                web_news = self.crag.web_search_fallback(ticker, base_query)
        
        # 6. Cross-Encoder Reranking
        if strategy["use_cross"] and self.cross_encoder.available:
            print(f"{Fore.MAGENTA}  â†’ Cross-Encoder: Ultra hassas sÄ±ralama...{Style.RESET_ALL}", flush=True)
            docs = self.cross_encoder.rerank(base_query, docs, top_k=3)
            print(f"{Fore.GREEN}  â†’ Cross-Encoder: {len(docs)} dÃ¶kÃ¼man{Style.RESET_ALL}", flush=True)
        else:
            docs = docs[:5]
        
        # 7. Parent Fetch
        docs = self._batch_fetch_parents(docs)
        
        # Context
        context = "\n\n---\n\n".join([f"[{d.metadata.get('category', '?')}] {d.page_content[:800]}" for d in docs[:3]])
        
        # 8. Trade Rule Extraction
        trade_rules = ""
        current_price = 0.0
        current_rsi = 40.0
        
        price_match = re.search(r'Fiyat:\s*([\d.]+)', tech_signals)
        rsi_match = re.search(r'RSI.*?:\s*([\d.]+)', tech_signals)
        if price_match:
            current_price = float(price_match.group(1))
        if rsi_match:
            current_rsi = float(rsi_match.group(1))
        
        if current_price > 0:
            trade_rules = self.rule_extractor.extract_trade_rules(docs, ticker, current_price)
            trade_rules += self.rule_extractor.calculate_levels(current_price, current_rsi)
            print(f"{Fore.GREEN}  â†’ Trade Rules: Entry/Exit seviyeleri hesaplandÄ±{Style.RESET_ALL}", flush=True)
        
        # 9. Python REPL
        calculations = self._execute_calculation(base_query, tech_signals)
        
        # 10. Graph-RAG
        graph_context = self.graph.get_graph_context(base_query)
        if graph_context:
            print(f"{Fore.MAGENTA}  â†’ Graph-RAG: Ekonomik iliÅŸkiler bulundu{Style.RESET_ALL}", flush=True)
        
        # 11. Memory
        personalization = self.memory.get_personalization_context(self.user_id)
        print(f"{Fore.CYAN}  â†’ SQLite Memory: Profil yÃ¼klendi{Style.RESET_ALL}", flush=True)
        
        # 12. Fact-Check
        fact_check = ""
        if YFINANCE_AVAILABLE and ticker not in ["GENEL", "EURUSD"]:
            try:
                info = yf.Ticker(ticker).info
                price = info.get("regularMarketPrice", info.get("currentPrice"))
                if price:
                    change = ((price - info.get("previousClose", price)) / info.get("previousClose", price) * 100)
                    fact_check = f"\nâœ… CANLI: {ticker} ${price:.2f} ({change:+.2f}%)\n"
                    print(f"{Fore.GREEN}  â†’ Fact-Check: ${price:.2f}{Style.RESET_ALL}", flush=True)
            except:
                pass
        
        # Add context
        if web_news:
            context = web_news + "\n" + context
        if trade_rules:
            context = trade_rules + "\n" + context
        
        # 13. Backtest Learning
        past_performance = self.memory.analyze_past_performance(self.user_id)
        if past_performance:
            print(f"{Fore.CYAN}  â†’ Backtest Learning: GeÃ§miÅŸ dersler yÃ¼klendi{Style.RESET_ALL}", flush=True)
        
        # 14. Agentic Tool Planning
        if complexity == QueryComplexity.COMPLEX:
            planned_tools = self.agentic.plan_tools(base_query)
            print(f"{Fore.MAGENTA}  â†’ Agentic: Planlanan araÃ§lar: {planned_tools}{Style.RESET_ALL}", flush=True)
        
        # 15. LLM Generation
        template = self._get_prompt(complexity == QueryComplexity.COMPLEX)
        prompt = ChatPromptTemplate.from_template(template)
        
        chain = ({
            "context": lambda x: context,
            "ticker": lambda x: ticker,
            "tech_signals": lambda x: tech_signals,
            "market_sentiment": lambda x: market_sentiment,
            "fact_check": lambda x: fact_check,
            "personalization": lambda x: personalization,
            "graph_context": lambda x: graph_context,
            "calculations": lambda x: calculations,
            "past_performance": lambda x: past_performance
        } | prompt | self.llm | StrOutputParser())
        
        try:
            print(f"{Fore.YELLOW}  â†’ LLM: AI Lab analiz...{Style.RESET_ALL}", flush=True)
            response = chain.invoke(base_query)
            
            action = "BEKLE"
            if "AL" in response.upper():
                action = "AL"
            elif "SAT" in response.upper():
                action = "SAT"
            
            self.memory.add_recommendation(self.user_id, ticker, action, 85)
            
            print(f"{Fore.GREEN}âœ… AI Lab analiz tamamlandÄ±{Style.RESET_ALL}", flush=True)
            return response
        except Exception as e:
            return f"âŒ Hata: {str(e)}"


# ============================================
# HELPER FUNCTIONS
# ============================================
def set_user_preference(advisor: AIAdvisor, key: str, value: str):
    """KullanÄ±cÄ± tercihini gÃ¼ncelle."""
    advisor.memory.update_preference(advisor.user_id, key, value)
    print(f"{Fore.GREEN}âœ… Tercih gÃ¼ncellendi: {key} = {value}{Style.RESET_ALL}")
