# ============================================================
# NeuralTrade - Production Docker Compose (GPU Optimized)
# ============================================================
# Stack: Python Bot (GPU), NestJS, TimescaleDB, Redis, Qdrant, Monitoring
# Hardware Target: NVIDIA GTX 1650 Ti (4GB VRAM)
# ============================================================

version: '3.8'

services:
  # ============================================================
  # Layer 5: PostgreSQL + TimescaleDB (Primary DB)
  # ============================================================
  postgres:
    image: timescale/timescaledb:2.13.1-pg16
    container_name: neuraltrade-postgres
    restart: unless-stopped
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=neuraltrade
      - POSTGRES_PASSWORD=neuraltrade_secret
      - POSTGRES_DB=neuraltrade
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./infrastructure/postgres/init-timescale.sql:/docker-entrypoint-initdb.d/init-timescale.sql:ro
    networks:
      - neuraltrade-net
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U neuraltrade -d neuraltrade"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ============================================================
  # Layer 3: NestJS Backend (Application Core)
  # ============================================================
  neuraltrade-be:
    build:
      context: ./neuraltrade-be
      dockerfile: Dockerfile
    container_name: neuraltrade-backend
    restart: unless-stopped
    ports:
      - "4000:3000"    # Host:Container (expose as 4000 externally)
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://postgres.xfjbapqmqperijjawwgq:Trabzonspor61ts!1967@aws-1-us-east-1.pooler.supabase.com:6543/postgres?pgbouncer=true
      - DIRECT_URL=postgresql://postgres.xfjbapqmqperijjawwgq:Trabzonspor61ts!1967@aws-1-us-east-1.pooler.supabase.com:5432/postgres
      - REDIS_URL=redis://redis:6379
      - AI_BOT_URL=http://neuraltrade:8000
      - AI_GRPC_HOST=neuraltrade
      - AI_GRPC_PORT=50051
      - JWT_SECRET=${JWT_SECRET:-neuraltrade_jwt_secret_change_me}
      - JWT_EXPIRATION=7d
      - ENABLE_SWAGGER=true
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - neuraltrade-net
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/api/v1/health/live"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ============================================================
  # Layer 2: Nginx API Gateway (SSL Termination)
  # ============================================================
  nginx:
    image: nginx:1.25-alpine
    container_name: neuraltrade-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./infrastructure/nginx/nginx.conf:/etc/nginx/conf.d/default.conf:ro
      - ./infrastructure/nginx/ssl:/etc/nginx/ssl:ro
    depends_on:
      - neuraltrade-be
    networks:
      - neuraltrade-net
    profiles:
      - gateway
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # ============================================================
  # cadvisor - Container Metrics (Docker Stats)
  # ============================================================
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.47.2
    container_name: neuraltrade-cadvisor
    restart: unless-stopped
    ports:
      - "8080:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    networks:
      - neuraltrade-net
    profiles:
      - monitoring
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # ============================================================
  # Main Trading Bot (GPU Enabled & Crash Fixed)
  # ============================================================
  neuraltrade:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        PYTHON_VERSION: "3.11"
        TA_LIB_VERSION: "0.4.0"
    container_name: neuraltrade-bot
    restart: unless-stopped
    ports:
      - "8000:8000"   # API
      - "50051:50051" # gRPC
      - "9090:9090"   # Metrics
    environment:
      # ðŸš€ GPU & PERFORMANS AYARLARI
      - PYTHONOPTIMIZE=1                          # âœ… CRASH FIX (Transformers)
      - NVIDIA_VISIBLE_DEVICES=all                # âœ… GPU FIX
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128  # âœ… VRAM FIX (1650 Ti 4GB)
      
      # âš™ï¸ UYGULAMA AYARLARI
      - NEURALTRADE_ENV=production
      - REDIS_URL=redis://redis:6379
      - QDRANT_URL=http://qdrant:6333
      - LOG_LEVEL=INFO
      - PYTHONPATH=/app
      
      # ðŸ§  AI KÃœTÃœPHANE AYARLARI
      - USE_TORCH=1
      - USE_TF=1
      - TRANSFORMERS_NO_TF=0

      # ðŸ“‚ HUGGINGFACE CACHE (KalÄ±cÄ± KlasÃ¶re YÃ¶nlendirme)
      # Not: Dockerfile iÃ§inde de set ettik ama buradan override etmek garantidir.
      
      - HF_HUB_CACHE=/app/data/huggingface/hub
      
      - SENTENCE_TRANSFORMERS_HOME=/app/data/huggingface/sentence-transformers
      - HF_HUB_DISABLE_TELEMETRY=1
      
    volumes:
      - ./data:/app/data     # Veri ve Modeller burada saklanÄ±r
      - ./logs:/app/logs
      - ./config:/app/config
    depends_on:
      redis:
        condition: service_healthy
      qdrant:
        condition: service_started
    networks:
      - neuraltrade-net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    
    # ðŸ‘‡ GPU REZERVASYONU (ÅžART) ðŸ‘‡
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ============================================================
  # Redis - Cache & Message Queue
  # ============================================================
  redis:
    image: redis:7-alpine
    container_name: neuraltrade-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes --maxmemory 2gb --maxmemory-policy noeviction
    networks:
      - neuraltrade-net
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # ============================================================
  # Qdrant - Vector Database (AI RAG)
  # ============================================================
  qdrant:
    image: qdrant/qdrant:v1.7.4
    container_name: neuraltrade-qdrant
    restart: unless-stopped
    ports:
      - "6333:6333"   # HTTP API
      - "6334:6334"   # gRPC API
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334
    volumes:
      - qdrant-data:/qdrant/storage
    networks:
      - neuraltrade-net
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # ============================================================
  # Prometheus - Metrics Collection
  # ============================================================
  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: neuraltrade-prometheus
    restart: unless-stopped
    ports:
      - "9091:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./recording_rules.yml:/etc/prometheus/recording_rules.yml:ro
      - ./alerting_rules.yml:/etc/prometheus/alerting_rules.yml:ro
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    networks:
      - neuraltrade-net
    depends_on:
      - neuraltrade
    profiles:
      - monitoring
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ============================================================
  # Grafana - Dashboards & Visualization
  # ============================================================
  grafana:
    image: grafana/grafana:10.2.0
    container_name: neuraltrade-grafana
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=neuraltrade123
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_ROOT_URL=http://localhost:3000
      - GF_INSTALL_PLUGINS=redis-datasource
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./grafana/datasources:/etc/grafana/provisioning/datasources:ro
    depends_on:
      - prometheus
    networks:
      - neuraltrade-net
    profiles:
      - monitoring
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # ============================================================
  # Node Exporter - System Metrics
  # ============================================================
  node-exporter:
    image: prom/node-exporter:v1.7.0
    container_name: neuraltrade-node-exporter
    restart: unless-stopped
    ports:
      - "9100:9100"
    networks:
      - neuraltrade-net
    profiles:
      - monitoring
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # ============================================================
  # Alertmanager - Alert Management
  # ============================================================
  alertmanager:
    image: prom/alertmanager:v0.26.0
    container_name: neuraltrade-alertmanager
    restart: unless-stopped
    ports:
      - "9093:9093"
    volumes:
      - ./alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
      - alertmanager-data:/alertmanager
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--web.external-url=http://localhost:9093'
    networks:
      - neuraltrade-net
    profiles:
      - monitoring
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # ============================================================
  # MLflow - ML Experiment Tracking & Model Registry
  # ============================================================
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.10.0
    container_name: neuraltrade-mlflow
    restart: unless-stopped
    ports:
      - "5000:5000"
    environment:
      - MLFLOW_TRACKING_URI=sqlite:///mlflow/mlflow.db
      - MLFLOW_ARTIFACT_ROOT=/mlflow/artifacts
    volumes:
      - mlflow-data:/mlflow
    command: >
      mlflow server
      --backend-store-uri sqlite:///mlflow/mlflow.db
      --default-artifact-root /mlflow/artifacts
      --host 0.0.0.0
      --port 5000
    networks:
      - neuraltrade-net
    profiles:
      - ml
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # ============================================================
  # Test Runner (Profile: test)
  # ============================================================
  neuraltrade-test:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: neuraltrade-test
    command: ["python", "tests/test_math_simple.py"]
    environment:
      - NEURALTRADE_ENV=test
      - PYTHONIOENCODING=utf-8
    volumes:
      - ./tests:/app/tests:ro
      - ./modules:/app/modules:ro
    networks:
      - neuraltrade-net
    profiles:
      - test

  # ============================================================
  # Pipeline Runner (Profile: pipeline)
  # ============================================================
  neuraltrade-pipeline:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: neuraltrade-pipeline
    command: ["python", "pipeline.py"]
    environment:
      - NEURALTRADE_ENV=production
      - REDIS_URL=redis://redis:6379
      - PYTHONOPTIMIZE=1 # Buna da ekledik, ne olur ne olmaz
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - neuraltrade-net
    profiles:
      - pipeline
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

# ============================================================
# Networks
# ============================================================
networks:
  neuraltrade-net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16

# ============================================================
# Volumes
# ============================================================
volumes:
  postgres-data:
    driver: local
  redis-data:
    driver: local
  qdrant-data:
    driver: local
  prometheus-data:
    driver: local
  grafana-data:
    driver: local
  alertmanager-data:
    driver: local
  mlflow-data:
    driver: local